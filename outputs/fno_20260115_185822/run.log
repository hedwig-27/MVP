2026-01-15 18:58:22,270 | INFO | Log file: outputs/fno_20260115_185822/run.log
2026-01-15 18:58:27,912 | INFO | Dataset[0] adv_beta0.1 params=[0.10000000149011612, 0.0, 0.0] train_pairs=6400 val_pairs=800 test_pairs=800 weight=1.0
2026-01-15 18:58:27,925 | INFO | Dataset[1] adv_beta0.4 params=[0.4000000059604645, 0.0, 0.0] train_pairs=6400 val_pairs=800 test_pairs=800 weight=1.0
2026-01-15 18:58:27,925 | INFO | Dataset[2] adv_beta1.0 params=[1.0, 0.0, 0.0] train_pairs=6400 val_pairs=800 test_pairs=800 weight=1.0
2026-01-15 18:58:27,925 | INFO | Dataset[3] burgers_nu0.001 params=[0.0, 0.0010000000474974513, 0.0] train_pairs=6400 val_pairs=800 test_pairs=800 weight=1.0
2026-01-15 18:58:27,925 | INFO | Dataset[4] burgers_nu0.01 params=[0.0, 0.009999999776482582, 0.0] train_pairs=6400 val_pairs=800 test_pairs=800 weight=1.0
2026-01-15 18:58:27,925 | INFO | Dataset[5] burgers_nu0.1 params=[0.0, 0.10000000149011612, 0.0] train_pairs=6400 val_pairs=800 test_pairs=800 weight=1.0
2026-01-15 18:58:27,925 | INFO | Dataset[6] reacdiff_rho1 params=[0.0, 0.5, 1.0] train_pairs=3200 val_pairs=400 test_pairs=400 weight=1.0
2026-01-15 18:58:27,925 | INFO | Dataset[7] reacdiff_rho5 params=[0.0, 0.5, 5.0] train_pairs=3200 val_pairs=400 test_pairs=400 weight=1.0
2026-01-15 18:58:27,925 | INFO | Dataset[8] diff_sorp params=[0.0, 0.0, 0.0] train_pairs=3200 val_pairs=400 test_pairs=400 weight=1.0
2026-01-15 18:59:24,286 | INFO | Val Loss (adv_beta0.1): 0.074785
2026-01-15 18:59:25,093 | INFO | Val Loss (adv_beta0.4): 0.033836
2026-01-15 18:59:25,858 | INFO | Val Loss (adv_beta1.0): 0.024067
2026-01-15 18:59:26,659 | INFO | Val Loss (burgers_nu0.001): 0.017159
2026-01-15 18:59:27,465 | INFO | Val Loss (burgers_nu0.01): 0.014354
2026-01-15 18:59:28,238 | INFO | Val Loss (burgers_nu0.1): 0.005017
2026-01-15 18:59:28,895 | INFO | Val Loss (reacdiff_rho1): 0.001881
2026-01-15 18:59:29,550 | INFO | Val Loss (reacdiff_rho5): 0.003197
2026-01-15 18:59:30,175 | INFO | Val Loss (diff_sorp): 0.003725
2026-01-15 18:59:30,175 | INFO | [Epoch 1] Train Loss: 0.022181, Val Loss: 0.022989
2026-01-15 19:00:16,179 | INFO | Val Loss (adv_beta0.1): 0.028532
2026-01-15 19:00:16,456 | INFO | Val Loss (adv_beta0.4): 0.008469
2026-01-15 19:00:16,727 | INFO | Val Loss (adv_beta1.0): 0.061647
2026-01-15 19:00:16,975 | INFO | Val Loss (burgers_nu0.001): 0.012438
2026-01-15 19:00:17,232 | INFO | Val Loss (burgers_nu0.01): 0.010073
2026-01-15 19:00:17,501 | INFO | Val Loss (burgers_nu0.1): 0.004609
2026-01-15 19:00:17,672 | INFO | Val Loss (reacdiff_rho1): 0.002219
2026-01-15 19:00:17,841 | INFO | Val Loss (reacdiff_rho5): 0.004017
2026-01-15 19:00:18,015 | INFO | Val Loss (diff_sorp): 0.002011
2026-01-15 19:00:18,016 | INFO | [Epoch 2] Train Loss: 0.016711, Val Loss: 0.017203
2026-01-15 19:01:04,424 | INFO | Val Loss (adv_beta0.1): 0.030559
2026-01-15 19:01:04,694 | INFO | Val Loss (adv_beta0.4): 0.013182
2026-01-15 19:01:04,978 | INFO | Val Loss (adv_beta1.0): 0.065358
2026-01-15 19:01:05,243 | INFO | Val Loss (burgers_nu0.001): 0.011260
2026-01-15 19:01:05,503 | INFO | Val Loss (burgers_nu0.01): 0.008925
2026-01-15 19:01:05,776 | INFO | Val Loss (burgers_nu0.1): 0.004816
2026-01-15 19:01:05,945 | INFO | Val Loss (reacdiff_rho1): 0.000530
2026-01-15 19:01:06,101 | INFO | Val Loss (reacdiff_rho5): 0.001195
2026-01-15 19:01:06,254 | INFO | Val Loss (diff_sorp): 0.001640
2026-01-15 19:01:06,255 | INFO | [Epoch 3] Train Loss: 0.014810, Val Loss: 0.017970
2026-01-15 19:01:53,230 | INFO | Val Loss (adv_beta0.1): 0.030733
2026-01-15 19:01:53,514 | INFO | Val Loss (adv_beta0.4): 0.020486
2026-01-15 19:01:53,773 | INFO | Val Loss (adv_beta1.0): 0.082382
2026-01-15 19:01:54,044 | INFO | Val Loss (burgers_nu0.001): 0.008982
2026-01-15 19:01:54,335 | INFO | Val Loss (burgers_nu0.01): 0.006777
2026-01-15 19:01:54,616 | INFO | Val Loss (burgers_nu0.1): 0.003328
2026-01-15 19:01:54,774 | INFO | Val Loss (reacdiff_rho1): 0.000979
2026-01-15 19:01:54,925 | INFO | Val Loss (reacdiff_rho5): 0.000782
2026-01-15 19:01:55,105 | INFO | Val Loss (diff_sorp): 0.001546
2026-01-15 19:01:55,105 | INFO | [Epoch 4] Train Loss: 0.014486, Val Loss: 0.020424
2026-01-15 19:02:41,580 | INFO | Val Loss (adv_beta0.1): 0.039844
2026-01-15 19:02:41,872 | INFO | Val Loss (adv_beta0.4): 0.016019
2026-01-15 19:02:42,155 | INFO | Val Loss (adv_beta1.0): 0.052409
2026-01-15 19:02:42,465 | INFO | Val Loss (burgers_nu0.001): 0.009606
2026-01-15 19:02:42,755 | INFO | Val Loss (burgers_nu0.01): 0.007420
2026-01-15 19:02:43,049 | INFO | Val Loss (burgers_nu0.1): 0.003822
2026-01-15 19:02:43,215 | INFO | Val Loss (reacdiff_rho1): 0.000477
2026-01-15 19:02:43,398 | INFO | Val Loss (reacdiff_rho5): 0.000633
2026-01-15 19:02:43,570 | INFO | Val Loss (diff_sorp): 0.001393
2026-01-15 19:02:43,570 | INFO | [Epoch 5] Train Loss: 0.013792, Val Loss: 0.017252
2026-01-15 19:02:44,389 | INFO | Test Loss (burgers_nu1): 0.004513
2026-01-15 19:02:45,187 | INFO | Test Loss (reacdiff_rho10): 0.001820
2026-01-15 19:02:45,187 | INFO | Test Loss (avg): 0.003591
2026-01-15 19:02:45,189 | INFO | Baseline FNO training complete. Model saved to: outputs/fno_20260115_185822/fno_model.pt
2026-01-15 19:02:52,097 | INFO | Log file: /home/lgz/workspace/MVP/outputs/fno_20260115_185822/run.log
2026-01-15 19:37:04,641 | INFO | Log file: /home/lgz/workspace/MVP/outputs/fno_20260115_185822/run.log
2026-01-15 19:40:28,119 | INFO | Log file: /home/lgz/workspace/MVP/outputs/fno_20260115_185822/run.log
2026-01-15 19:40:40,317 | INFO | One-step MSE (adv_beta0.1): 0.034495
2026-01-15 19:40:41,551 | INFO | One-step MSE (adv_beta0.4): 0.007550
2026-01-15 19:40:42,784 | INFO | One-step MSE (adv_beta1.0): 0.064795
2026-01-15 19:40:44,021 | INFO | One-step MSE (burgers_nu0.001): 0.007596
2026-01-15 19:40:45,267 | INFO | One-step MSE (burgers_nu0.01): 0.005378
2026-01-15 19:40:46,501 | INFO | One-step MSE (burgers_nu0.1): 0.002725
2026-01-15 19:40:47,823 | INFO | One-step MSE (reacdiff_rho1): 0.002399
2026-01-15 19:40:48,929 | INFO | One-step MSE (reacdiff_rho5): 0.004363
2026-01-15 19:40:50,140 | INFO | One-step MSE (diff_sorp): 0.002001
2026-01-15 19:40:50,140 | INFO | One-step MSE (avg): 0.016812
