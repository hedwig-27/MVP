实验扩展计划方案

为了进一步验证和完善当前 MVP 项目（自动发现神经算子原语 Primitive Operators）的表现、结构设计合理性、泛化能力以及原语分工机制，我们制定了以下系统的实验扩展计划。整个计划分为四大部分，对应题目所述的四类实验方向，每一部分都明确实验目的、方法、评估指标和技术实现建议。

1. Ablation 实验

目的： 通过消融（Ablation）实验来评估各组件和设计对模型性能与原语分化的影响。具体包括：移除路由器的稀疏机制、去除原语输出多样性正则项、改变原语算子数量，以及调整路由器输入特征。这些实验将揭示各要素在模型中的作用，验证模型结构设计的合理性。

1.1 去除路由器稀疏性（禁用 Top-k 选择）

实验动机： 默认的路由器使用 Top-k 稀疏路由机制，每次仅激活得分最高的 $k$ 个原语算子。这有助于专家模型的分工和计算效率，但可能也限制信息流通。为了评估稀疏 gating 对性能和原语专门化的影响，我们考虑去掉这种稀疏性，让路由器同时利用所有原语（即不使用 Top-k 截断）。

实验方法： 将路由器的 top_k 参数设为等于原语总数（例如 top_k = num_primitives），从而变为密集路由（即 Softmax 加权所有原语输出）。训练模型并观察其性能变化。比较禁用 Top-k 后模型的训练收敛、预测精度以及原语使用情况，与默认 Top-k=2 的基线进行对比。

评估指标： 采用与基线相同的评价指标，包括测试集 MSE（包括 IID 测试和参数外推 OOD 测试）、Rollout 长时预测误差以及训练稳定性等。重点关注：(1) 准确率变化：无稀疏 gating 时性能是否提升或下降；(2) 原语使用分布：统计每个原语被赋予的平均权重或贡献占比，是否出现权重平均化或相反地出现某些原语主导；(3) 原语分工：分析原语输出的差异性是否减弱（可能因为所有原语同时参与而变得同质化）。

实现建议： 代码层面只需修改配置将路由器 Top-k 设为与原语数量相同（模型内部实现中，若 top_k == num_primitives 则不会屏蔽任何原语权重）。训练时可适当减少熵损失权重（如果有的话），以免鼓励过度平均化。还需注意计算开销增加：同时激活所有原语将增加每步计算量，因此在保持网络宽度不变情况下，禁用 Top-k 可能需要权衡批大小或网络规模以避免显存瓶颈。

1.2 去除原语输出多样性正则项

实验动机： 模型训练中引入了原语输出差异性的正则化项（diversity loss），鼓励各原语算子的输出彼此正交或不同，以防止原语塌缩（所有原语学到相似的功能）。我们希望验证该正则项对模型性能和原语分工的实际作用。通过去掉该正则项，可以观察模型是否会出现原语功能重合、部分原语闲置等现象，从而评估正则项的重要性。

实验方法： 将训练配置中的 diversity_weight 设置为 0（禁用多样性正则），其余条件与基线保持一致，训练模型。对比有无该正则项时模型的原语使用情况和性能差异。必要时，也可分别对比降低一半和提高一倍多样性权重的情况，以观察规律。

评估指标： 除基本的误差指标（测试 MSE、rollout误差等）外，着重考察：(1) 原语输出相似度：利用与训练时相同的多样性度量，计算各原语输出之间的平均余弦相似度。预期如果无正则，原语输出会更相似（相似度升高）。(2) 原语使用频率：统计各原语被选为 Top-k 的频率占比。如发现某些原语长期权重接近0或很少被选中，即表示出现塌缩或闲置情况。(3) 模型精度：比较有无正则时的验证/测试误差，验证正则项对模型泛化的影响。如果无正则导致若干原语输出近似相同，则有效模型容量降低，可能使整体性能下降。

实现建议： 修改训练脚本中的损失函数，去掉或设置多样性损失权重为零。训练过程中记录每个 epoch 的原语间相似度矩阵（使用 _diversity_penalty 函数计算），以及每个原语平均权重，随时间绘制曲线观察变化趋势。如发现训练早期即有原语权重趋零，可考虑启发式干预（例如重新初始化该原语或暂时提高熵正则促进探索）。实验后，通过对比如上指标，总结多样性约束对原语分工机制的作用。

1.3 原语算子数量对性能与分化的影响

实验动机： 原语数量是模型的关键超参数，它决定了模型最大可分解出多少种基础动力学模式。我们希望探究原语数目的不同取值（例如 4、8、16、32）对模型预测性能和原语分化程度的影响，找到合理的原语数量范围。较少的原语可能限制模型表达能力，而过多的原语可能造成资源浪费或训练不稳定（许多原语可能闲置）。

实验方法： 按相同的数据集和训练超参数（除了原语数）分别训练模型，设置原语数量 $N_p \in {4, 8, 16, 32}$（原始基线为6个）。保持路由器的 Top-k 比例固定，例如一直用 $k=2$，以观察在不同 $N_p$ 下稀疏激活的效果。如果计算资源允许，也可以在较大 $N_p$ 情况下尝试提高 $k$ 值（如 $k=4$），但主要实验重点是在相同 $k$ 下增加原语总数。训练完成后，对比不同 $N_p$ 下模型的误差、原语使用情况等。

评估指标： 主要包括：(1) 性能随原语数的曲线：绘制测试集误差随原语数量的变化，可作为对比基线，观察是否存在性能饱和点或拐点。例如，是否从4增至8显著降低误差，而16以后收益变小甚至恶化。(2) 原语利用率：计算每种设置下实际被使用的原语个数（例如使用频率>5%的算作有效）。预期原语数过多时，一部分原语几乎从未被路由选中（利用率低），出现原语闲置/塌缩。可以统计有效原语比例随 $N_p$ 的变化，以及平均每个样本激活的原语多样性（如每时间步平均使用的不同原语数，或权重熵）。(3) 分工情况：对于较小和较大 $N_p$，分别分析原语功能是否有明显区分。原语输出的多样性指标可用于量化不同 $N_p$ 下分化程度。

实现建议： 在配置文件中设置不同的 model.num_primitives 值并批量运行实验。需要注意的是，增加原语数量会增加模型参数和计算量，训练时可能需要适当调整学习率或训练轮数以充分收敛。对于 $N_p=32$ 等较大模型，可监控训练过程中某些原语的梯度是否接近0（表明未学到有用功能）。若出现多数原语未被利用，可尝试增加熵正则权重鼓励更均匀的路由分配。实验结果整理时，可将性能和原语使用统计制成表格或折线图，清晰展示原语数目的影响。

1.4 路由器输入特征的变化

实验动机： 路由器决定了不同时刻/不同PDE下启用哪些原语，其输入特征对路由决策影响重大。当前实现中，路由器以状态场的低维统计量作为输入，包括均值、标准差、最小值、最大值，以及可选的 FFT 频谱片段和 PDE 参数等。我们将在这一实验中改变路由器的输入特征种类，评估不同特征组合对模型性能和原语选择行为的影响，从而验证现有路由特征设计的合理性并寻找可能的改进。

实验方法： 针对以下几种特征方案分别训练并比较：

不使用 PDE 参数： 将路由器配置中的 pde_param_dim 设为0，即路由器不了解显式的方程参数，仅根据状态本身决定组合。这可以测试显式参数输入对模型泛化的贡献。对比如将参数（如 $\nu, \beta$ 等）加入路由的基线，观察有无参数输入在跨参数泛化上的差异。

加入频域特征： 设置 fft_bins > 0 以加入状态场的频谱幅值作为额外输入。频域信息可以帮助路由器判别状态的粗细尺度特征（例如是否出现高频振荡），从而可能更好地区分例如扩散主导 vs. 对流主导的情形。实验将比较有无 FFT 特征时的模型表现，尤其关注那些在时空频率上差异明显的PDE（如KS方程具有高频不稳定模态）。

空间局部特征： 改变仅用全局统计的做法，尝试引入分区/局部 patch 的统计。例如将空间域划分为若干段，计算每段的均值/方差，或取状态在网格上的下采样值作为路由输入。这将提供状态的空间分布信息，可能帮助路由器在单个时间步内做出更细粒度的决策。由于现有路由器是对整个 $u(x)$ 输出统一权重，我们也考虑实现一种分片路由策略：即根据局部特征在不同空间位置选择原语。不过，该改进较为复杂，在此阶段主要先尝试将多个局部统计量并入路由输入向量，保持单一组合权重看看效果。

评估指标： 比较不同路由输入配置下：(1) 预测性能：包括各数据集的测试误差和rollout稳定性。如果某种输入能捕捉关键动态，则应提升性能或减少对分布外参数的误差。(2) 泛化能力：关注路由使用PDE参数 vs 不使用时，对参数外推的影响。例如，不提供参数时模型能否仅凭状态统计量泛化到未见参数？或者提供参数后，对那些状态差异不大的情形能否更好地区分？(3) 路由决策的一致性：分析路由器在不同任务/参数下输出的原语权重。如果加入FFT等特征，我们期望看到路由对高频内容敏感（例如在KS方程中偏好某些原语）。若使用局部特征，观察路由权重是否对不同初值形态更有区分度。还可以比较权重分布的熵或方差，评估路由决策是否更明确或更含糊。

实现建议： 配置层面，利用已有路由器代码的参数灵活性：例如启用 fft_bins（选择若干频率bins数）以及传入或屏蔽 pde_params。对于局部特征，需要修改路由器的 _compute_stats 方法：可以在代码中对输入 $u(x)$ 按空间划分，例如每256个网格点为一段，分别计算均值/方差，然后将这些值串联到特征向量。也可考虑更复杂的方法，如用一个小型卷积网络提取状态的低维表示作为路由输入**(需注意保持路由计算开销较低)**。在实现新的特征后，确保对不同PDE数据都适用（例如FFT需要统一网格长度，如果各数据集网格数不同，可在数据预处理中插值或固定取前N频率系数）。实验过程中记录每种路由器配置的训练收敛速度和最终结果，以确定哪种特征组合对性能/泛化最有利。

2. 组合机制扩展

目的： 探索原语组合从线性加权和扩展到非线性组合的方法对模型性能和可解释性的影响。当前模型采用线性加权求和 ($u_{t+1} = u_t + \sum_i \alpha_i \Delta u_i$)，这种线性组合易于解释：权重直接反映各原语贡献。然而，对于非线性动力学（如 Burgers 方程中对流项 $u \partial_x u$ 的耦合），线性组合可能不足以捕获复杂相互作用。因此，我们计划引入非线性组合机制（例如通过小型 MLP 将多个原语输出进行组合），并比较两种方式在性能、解释性和原语分工上的差异。

2.1 线性 vs. 非线性原语组合方式

方法设计： 保留原语算子模块不变，引入一个组合器模块来替代简单加权和：例如定义一个两层左右的 MLP（或1x1卷积）作为Aggregator，接受多个原语算子的输出${\Delta u_i}$，输出最终的增量$\Delta u$。文献中的 CompNO 框架采用了类似思想：针对线性可加的对流-扩散方程使用线性组合，而对 Burgers 等非线性方程则使用带激活函数的两层感知机组合。在我们的实验中，考虑两种实现方案： (i) 仍采用 Top-k 稀疏选择原语，但用 MLP 取代加权平均组合这 $k$ 个原语的输出；(ii) 完全使用 MLP处理所有原语输出（可视为 gating 和组合一体化，由 MLP 自行学会忽略不需要的原语）。方案(i)计算更高效且保留一定稀疏性，有助于解释，而方案(ii)更灵活但可能需要更多数据支撑。优先实现方案(i)：如每步选出前2个原语$\Delta u_{i_1}, \Delta u_{i_2}$，将它们以及对应权重$\alpha_{i_1},\alpha_{i_2}$作为输入（4个量，或者直接输入两个场$\Delta u$在每个空间点的值），通过一个小 MLP 输出融合后的$\Delta u$场。

评估指标： 对比线性组合模型与非线性组合模型在相同数据集上的表现：(1) 误差性能：包括ID测试误差和OOD泛化。特别关注复杂非线性PDE（如 Burgers、Kuramoto-Sivashinsky）的长时模拟精度是否因非线性组合而提升。若非线性组合更好地近似了诸如$u\cdot \partial_x u$这类相乘项，预期在这类方程上误差降低。的研究指出仅线性叠加无法表示 Burgers 方程的复杂耦合，因此我们验证MLP组合能否缩小这一差距。(2) 解释性与分工：线性组合下，每个原语的权重易于解读，而引入MLP后，组合关系变为黑箱。我们将尝试衡量非线性组合的可解释性，例如：分析MLP内部权重或对输入的敏感性，观察是否仍可归因到某些原语起主要作用。还可以比较原语输出的专门化程度是否变化——例如MLP组合可能允许原语学到更加纯粹的基础操作（因为MLP可以负责非线性耦合），从而增强分工；也可能因为MLP的存在降低对单个原语质量的要求，使原语间界限变模糊。我们可通过计算原语输出多样性和使用频率来看非线性组合对分工的影响。

技术实现： 在代码上，新建一个组合器类（如 AggregatorMLP），在 PrimitiveCNO.forward 中替换掉原有的加权求和逻辑。对于方案(i)，可在获得 Top-k 原语指数后，将对应 $\Delta u$ 堆叠并送入组合器网络；对于方案(ii)，则将所有 $\Delta u$ 堆叠（可先经过一层降维）。组合器可以是对每个空间位置独立的全连接网络（输入维度=k个原语输出值，隐藏层尺寸小，输出1个值作为该位置的增量），也可以是带卷积的网络对整段场进行处理。需确保组合器的参数量相对于原模型不是太大，以免难以训练。训练阶段可以与原模型端到端联合训练（因为我们不预先训练原语），学习率等保持一致。为公平比较，应在相同数据集上分别训练“线性版”和“非线性版”模型若干轮次。实验分析时，可以绘制例如 Burgers 方程上时间演化的预测对比，观察非线性组合是否捕捉到了冲击形成等复杂行为。我们也可以参考 CompNO 提出的两种组合器的实验结果，以帮助推断我们观察到的趋势是否一致。

3. 数据集与任务扩展

目的： 验证模型在更多类型的方程和更高维度上的适应能力，并测试模型的跨任务泛化表现。本部分包括三个方面：(1) 在 PDEBench-1D 基准中引入更多种类的 PDE（如 Allen–Cahn 方程、Kuramoto–Sivashinsky 方程等），考察我们的原语发现方法在这些新动力学上的效果；(2) 将模型扩展到 PDEBench-2D 数据，检查模型结构在二维问题上的兼容性和表现；(3) 设计“留一类”实验，训练时故意缺失某类PDE以测试模型的组合泛化能力，即模型能否利用已学原语组合去近似一个未经训练的动力学。

3.1 增加 PDEBench-1D 的方程种类 (Allen–Cahn, KS 等)

实验目的： 将模型应用到更多样的1D PDE类型，验证方法的通用性和局限。Allen–Cahn方程代表反应-扩散系统中的双稳态非线性反应项，Kuramoto–Sivashinsky (KS) 方程则包含高阶非线性和耗散项，产生湍乱的时空混沌。通过在这些新数据集上的实验，我们可以评估原语算子能否自动学习到例如“双稳反应”或“高阶耗散”这样的新算子类型，以及模型在更加复杂动力学下的预测精度。

实验方法： 利用 PDEBench 提供的或自定义生成的方法获取Allen–Cahn和KS方程的一维模拟数据集（如10000组时间序列）。可以先在单一PDE数据集上训练模型，以观察其针对该PDE能否找到合理的原语分解；然后在多PDE混合训练中加入这些数据，看模型能否统一处理更多种类的方程。在混合训练时，需要在data.datasets中新增对应数据集配置，并设置适当的采样权重确保训练覆盖均衡。如果Allen–Cahn或KS有不同参数或初始条件，我们也可将其中一些作为OOD测试。例如Allen–Cahn可以通过改变双稳态势参数或初始扰动幅度测试外推能力；KS方程则可通过改变系统长度（模式数量）或初始谱能量分布测试泛化。

评估指标： 相对于之前的基线（只含Advection/Burgers等），新增PDE的评估关注：(1) 单方程性能：Allen–Cahn和KS上的单步预测误差、Rollout长期模拟误差，与FNO等基线对比。由于KS的混沌性质，可报告它在短期内（如$t=10,20$）的误差随时间增长情况，以及长时间统计量（例如平均能谱）是否吻合。Allen–Cahn作为刚性反应项测试，可检查模型能否准确预测相界面的移动和稳定模式。(2) 原语分工：分析新方程下模型学到的原语。比如Allen–Cahn包含$-F'(u)$（双稳非线性项）和扩散$\partial_{xx}$，我们期望模型可能出现一个原语专门负责平滑（类似扩散），另一个产生双峰形状的反应驱动。提到“基础块”可以专门学习对流或扩散等算子，我们将检查我们的匿名原语是否自行对应到这些物理含义。具体做法：对Allen–Cahn，比较某原语输出和$-u+u^3$反应项的形状是否相似；对KS，检查某些原语是否学到了高阶导数（如$\partial_{xx}$或$\partial_{xxxx}$）的效果。可以定量计算原语输出与已知算子作用的结果之间的相关系数。(3) 多任务学习效果：在混合训练包含Allen–Cahn/KS时，观察模型是否能同时兼顾多种PDE且不降级已有任务性能。这可以通过与各单独训练模型的误差比较来评估 任务间迁移 情况。如果发现某新PDE显著难学导致其他任务性能下降，说明模型容量不足或原语数不够，可考虑增加原语数量或网络宽度再试。

技术实现： 首先确认数据集格式兼容：PDEBench 可能有提供Allen–Cahn和KS的数据（如 PDENNEval 基准提到2D Allen–Cahn，我们可自行产生日志中1D数据）。可以使用已有PDE仿真工具生成1D Allen–Cahn（例如使用中心差分+显式/隐式时间步，双稳势参数可设为典型值）和KS数据（KS可用已知的半隐式谱法生成）。将数据存储为与PDEBench格式一致的HDF5文件，并更新数据加载器。如果项目已有 Reaction-Diffusion 的模板，Allen–Cahn只是在反应项上换成双稳态非线性，可以基于ReactionDiff数据生成器修改。模型方面，无需结构改动——原语为FNO1d或CNN1d均可拟合这些动力学，但可能需要调节训练超参数（例如KS高度混沌，可能需要更小学习率和更长训练轮次确保稳定）。训练Allen–Cahn时注意时间步长要足够小以捕捉快变化，KS则注意截断长度足够长以含多个波长。最终，通过脚本跑评估和绘图，检查新增结果。如果可能，附上一些Allen–Cahn和KS预测vs真值的曲线图，有助于直观展示模型效果。

3.2 扩展到 PDEBench-2D 数据

实验目的： 检验MVP模型在二维PDE上的结构可行性和性能表现。这将验证原语算子和路由器设计是否容易拓展到更高维度。在2D情况下，PDE解的模式更加复杂（出现二维结构、旋涡等），我们期望模型依然可以通过一组二维原语算子来刻画这些模式，并通过路由器在不同物理场景间切换。实验将比较MVP模型与传统单一模型（如2D-FNO）的性能，评估引入原语的优势是否在二维任务上保持。

实验方法： 选择 PDEBench 中的若干二维数据集进行测试。例如：2D Allen–Cahn方程（二维相分离问题）、2D Darcy Flow（地下水渗流，椭圆型方程，可作为稳态场测试），或Navier–Stokes二维湍流数据（如果有提供，典型如2D Kolmogorov流）。首先，从简单的开始：Allen–Cahn 2D 是反应扩散类，可以看作我们1D Allen–Cahn的推广；Darcy流测试模型对稳态问题的适应。对每个选择的2D任务，使用与1D类似的流程：将数据加载，训练一个含若干2D原语的模型和一个2D-FNO基线模型进行对比。重点在Allen–Cahn 2D上看界面演化是否能捕获，在Darcy问题上看是否满足或接近物理约束（Darcy为泊松类方程，可在边界条件上检查精度）。

评估指标： (1) 预测误差：报告二维场的相对误差 $L^2$ 范数或MSE。如Allen–Cahn 2D可计算相分离形态的重建误差，Navier–Stokes可计算速度场的统计量（如涡量分布）差异。关注MVP模型是否优于单一模型，特别在跨参数变化时是否更稳健。（2）原语可解释性：在二维情况下，原语算子的物理含义同样值得研究。比如可能出现一个原语学到各向同性扩散（表现为模糊平滑二维图像），另一个学到各向同性对流（平移图像），等等。我们可以通过可视化每个原语算子对输入场的作用来分析。例如给定一个二维初始场，分别计算各原语输出$\Delta u_i(x,y)$，绘制其热力图，直观判断其作用模式（平滑、尖峰、旋转等）。如果有已知方程结构，也可比较原语输出与已知算子的结果（如比较某原语输出与拉普拉斯$\nabla^2 u$的近似程度）来赋予其物理意义。(3) 结构兼容性：考察模型在实现和效率上的表现，如训练收敛难度、推理速度等。在2D任务中，FNO的优势通常更明显，因为它利用FFT可以高效处理高维数据。我们的原语如果也是基于FNO2d实现，则应能类似扩展。但需要评估路由器输入在2D时是否充分——目前路由器用全局统计，可能在二维更复杂场景下不够，比如多个不连通结构的状态场光用均值/方差可能不足以区分。因此，也可以监测2D任务中路由决策是否稳定或出现困难（例如频繁选错原语导致误差偏大）。如果发现问题，可能需要改进路由输入（如加入二维频谱信息或更多统计）再实验。

技术实现： 将 PrimitiveOperator 扩展为支持2D输入。当前实现中有 FNO1D 和 CNN1d；可引入类似的 FNO2D（可参考 FNO 论文或PDEBench中2D FNO代码）以及Conv2d架构。为简便，可先尝试将每个原语算子改为一个 2D UNet或2D卷积网络 来近似进程（虽然没有频域优势，但实现快）。但最终最好使用FNO2D，以充分利用其高效表示远场关联的能力。路由器方面，需要调整 _compute_stats 使其接受 $(batch, H, W, channels)$ 的输入，计算全局均值等（操作类似但要改成2维）。其他如FFT特征也可扩展为对2D场做2D FFT后取功率谱。注意2D数据更大，fft_bins数量需要谨慎（可以取低频几个系数）。训练时，由于参数量增多，可以从较低分辨率数据集开始（如$64\times64$网格），逐步测试模型扩展性。在运行2D实验时，需要较高的GPU算力，可能减小batch_size或采用混合精度来适应。评估和可视化方面，可编写脚本输出2D场的图片对比真值，例如Allen–Cahn 2D的相分离图像，以及原语输出的热力图【6†Figure 6】。确认模型在2D上运行后，再进行更复杂的2D任务扩展。

3.3 “留一类”PDE的 OOD 泛化测试

实验目的： 检验模型是否具备组合泛化能力：即在训练集中缺失某一类 PDE的情况下，模型能否通过已有原语的组合来近似该未见过的动力学。这类似于考察模型的“零样本任务泛化”能力，验证原语是否学到了可重组的基础算子。成功的话，将表明模型具有一定的可组合性：比如学到了“扩散”和“对流”两个原语后，即使没直接见过“对流+扩散”方程，也能将二者叠加近似之。这是通往PDE通用解算器的重要一步。

实验方法： 从我们考虑的PDE集合中挑选一类在训练中完全不出现，仅在测试时评估。例如：

留出对流-扩散：训练集包含纯对流(Advection)方程和纯扩散(Diffusion)方程的数据（以及可能其它，如纯反应等），但不包含二者共同作用的方程。测试时用对流-扩散组合方程（例如具有同时$\beta \partial_x u$和$\nu \partial_{xx} u$项的方程，即CompNO论文中的Convection-Diffusion）检验模型。

留出反应-扩散：训练集包含纯扩散、以及其他如Burgers（对流+扩散）等，但不包含带有源项的反应扩散方程（如Allen–Cahn或一般的Reaction-Diffusion）。测试时评估模型对Allen–Cahn或某反应扩散的表现，看其能否利用学到的扩散原语和其他原语组合来近似反应项。

留出 Burgers 非线性对流：训练包含线性对流、扩散等，以及线性组合的PDE，但未见过非线性耦合的Burgers。测试用Burgers方程评估，检查模型是否能用已有原语（可能分别近似$u\partial_x u$的各部分）来模拟非线性行为。指出线性组合难以完全表示Burgers的非线性，因此这也是对模型极限的测试。

实验实现上，可以像题目提供结果那样，将某数据集仅作为 eval_datasets（OOD）而不加入 datasets 训练列表。训练过程不改变，仅改变训练数据组合。

评估指标： 对留出类别的PDE，在零样本条件下模型的预测误差。将其与两个基线比较：(i) 未经训练的FNO（纯粹零样本，很可能误差极大），(ii) 在该PDE单独训练的模型（近似lower bound的最佳情况）。如果我们的组合模型能够取得比随机猜测好很多且接近直接训练模型的精度，就证明了一定的泛化能力。具体指标包括单步MSE、长期rollout误差，以及相对于直接训练模型误差的比例增加。例如，如果零样本Burgers误差只比有训练时高20%，说明模型很大程度上组合出了Burgers动力学；如果高出数倍，则说明无法泛化。另一个要看的方面是原语使用模式：在未见过的新PDE上，模型路由器会倾向选择哪些原语？这可以帮助解释模型如何尝试组合已有原语。例如，对Conv-Diff方程测试时，是否自动结合了原来负责对流的原语和负责扩散的原语一起工作？若可以观察到这点，将是强有力的证据支持组合机制。相反，若路由器在OOD任务上倾向于某个与真实机制不符的原语（例如只使用了对流而忽略需要的扩散），则表明泛化受限。

实现建议： 确保训练集中不包含待测PDE的数据，并不要将其参数分布泄露给模型（例如若使用PDE参数输入，需注意未出现过的参数值）。训练完毕后，在评估脚本中加载留出PDE的数据进行测试，获取误差和路由信息。可以对该OOD任务做一个rollout预测并与真实解对比图，用于直观评估（如绘制Burgers冲击演化对比图）。若模型表现不佳，可以分析原因：是因为缺少合适的原语？还是因为组合方式线性有限？分析后可提出改进，例如在模型中增加一个未训练的空白原语看看能否自行调整，或者在路由策略上允许外推。当模型能够部分泛化时，也可考虑进一步微调(fine-tune)：比如用极少量留出PDE的数据微调模型，观察是否比从零训练收敛更快（这属于额外验证，证明原语库的可迁移性，但非本次主要目标）。

4. 分析与可视化

目的： 对训练得到的模型进行深入分析，从多方面了解原语算子的使用情况和功能分解，以验证模型的可解释性和发现潜在问题。将通过统计与可视化方法，探究每个原语的使用频率、输出模式与语义、是否存在塌缩现象，以及模型的组合路径是否符合人类对方程物理构成的理解。以下分别设计具体的分析方案：

4.1 原语使用频率统计与热力图

分析目的： 量化各原语算子在模型中的参与程度，评估是否实现了预期的工作分工。一方面可发现主导原语（经常被选用的）和闲置原语（很少被用的）；另一方面可以比较不同PDE类型下原语使用的差异，验证路由器是否根据动力学自动调整了原语组合。

分析方法： 使用训练好的模型，对验证集或测试集数据逐样本记录路由器选择的 Top-k 原语索引和对应权重。汇总统计每个原语被选中的频率以及平均权重占比。可以分别统计总体频率和分数据集频率：例如构建一个矩阵，行代表PDE数据集，列代表原语编号，值为该PDE中该原语被激活的百分比。将此矩阵可视化成热力图，颜色深浅表示使用频率高低。此外，针对时间序列数据，我们也可以分析随时间的使用变化：选取某个代表性序列，记录每个时间步选中了哪些原语，绘制原语选择随时间的曲线或堆叠图，看在解的不同阶段是否路由决策发生切换（例如初始阶段 vs 演化后期选用的原语是否不同）。

指标解释： 如果模型有效地学到了分工，我们预期不同PDE偏好使用不同的原语组合。例如，在对流类PDE上某个原语出现频率远高于在扩散类PDE上，而另一个原语相反。这将印证原语对应于特定物理作用。如果统计结果显示只有极少数原语承担了主要工作（例如6个原语里2个占据~70%以上使用率），则需注意是否存在塌缩或不必要的原语。另外，如果路由在同一序列的不同时刻切换原语，也表明模型根据状态改变动态调整了计算，这种行为是否合理需结合物理分析判断。例如，可能在KS方程的混沌阶段选用了擅长高频的原语，而在平稳阶段用了另一个原语。

实现建议： 在现有评估脚本中，利用 PrimitiveCNO.route() 或 forward(return_weights=True) 获取路由结果。编写代码遍历测试集中每个样本，一步预测模式下记录其权重向量，找出Top-k索引。累加计数后，用Python的绘图库（如matplotlib）绘制柱状图或热力图。由于已有脚本输出了整体原语使用占比图 primitive_usage.png，可在此基础上增加区分数据集的版本。例如输出 primitive_usage_by_dataset.png，直观展示不同任务对原语的使用偏好。如果需要更细粒度，还可以按PDE参数或时间分段统计。此外，计算路由熵（每样本的权重分布熵）作为辅助指标，看不同任务下路由决策的确定性差异：熵低意味着路由强烈偏向少数原语，熵高则权重较均匀。结合这些统计，我们将总结路由器在各种情形下的行为规律。

4.2 原语输出的空间分布与语义特化

分析目的： 深入理解每个原语算子的功能，探究它们是否分别学到了特定的物理语义（如“扩散算子”、“对流算子”等），以及它们在空间域上作用的分布特点。这有助于验证模型的解释性：尽管原语匿名，我们希望通过分析赋予它们物理意义。

分析方法： 选择若干具有代表性的状态 $u_t$（可以是来自验证集的一些样本，覆盖不同PDE和参数情形），将其分别输入每个原语算子，得到各自的 $\Delta u_i$ 输出。然后进行以下分析：

可视化输出场： 对于每个原语的输出$\Delta u_i(x)$，绘制曲线（1D情况）或图像（2D情况），与输入场对比。例如，如果某原语是扩散型，我们应当看到其输出在高梯度处有显著变化，整体表现为平滑输入。如果是对流型，输出可能是输入场的位移版（导数形式）。通过肉眼观察这些模式并结合PDE知识，初步判断每个原语担当的角色。

频谱分析： 将$\Delta u_i$做FFT，观察其频率成分。如果发现某个原语倾向产生高频成分的变化，而另一个主要是低频平滑，就可推断前者像细致结构（可能对应非线性不稳定项或色散项），后者像扩散（耗散高频）等。这定量上可通过计算输出对不同波数的增益来实现——例如输入为单一正弦模式时各原语输出振幅。

与已知算子的相关性： 定义几个理想的微分算子作用：如 $Op_{\text{diff}}(u) = \partial_{xx}u$（扩散），$Op_{\text{adv}}(u) = -c\partial_x u$（平移/对流），或者Allen–Cahn的 $Op_{\text{react}}(u) = f(u)$ 非线性反应等。对于选定的状态，计算这些理想算子的结果，与原语输出进行比较，例如计算皮尔逊相关系数或 $L^2$ 误差。如果某原语$\Delta u_i$与某理想算子的输出高度相关（相关系数接近1），则可以赋予该原语相应的物理解释。例如，如果$\Delta u_3 \approx 0.1 \partial_{xx}u$，则原语3基本充当了一个扩散算子。这种分析可验证模型是否真的将复杂方程分解为了熟悉的基元。

空间局部性： 检查每个原语输出在空间上的非零区域。如果发现某些原语只在状态的特定区域产生影响（例如激波前沿、界面处），则它们可能学到了局部特化的操作。可以通过阈值过滤输出，观察大于某阈值的区域长度或位置来判断。

预期结果： 期望看到每个原语具有相对清晰的职责划分，例如在之前结果中 P5、P6 被高频使用，推测它们对应主要动力学项。我们希望通过上述方法确认这种推测并细化：例如发现“原语5 = 扩散平滑算子”，“原语6 = 推进/对流算子”，“原语2 = 反应源项算子”等等。如果分析发现两个或多个原语输出形态几乎一致，只是系数不同，这表明存在冗余/塌缩（需要结合4.3讨论原因）。相反，如每个原语表现出独特的模式，则验证了原语发现机制确实提取了不同的基础算子。

实现建议： 编写脚本对选定样本计算 model.primitives[i](u_t) 获取所有 $\Delta u_i$。对于1D，可以简单地画曲线叠加比较；对2D，用imshow等画二维热图。可将多种分析综合在一个Jupyter Notebook中便捷查看。在计算理想算子时，需要已知PDE形式或自行构造（如通过差分近似 $\partial_x, \partial_{xx}$）。如果PDE参数已知，也需代入计算（如对流速度$c$等）。另外，可以考虑对单位基函数的响应：例如输入一个很窄的高斯峰或单位脉冲，看看各原语输出什么——这类似于得到其“脉冲响应/绿函数”，有助于理解算子性质（例如是否带有振荡，表明色散行为）。所有这些分析应在训练集之外的数据上验证，以避免训练过程过拟合解释偏差。最终将分析结果整理成对于每个原语的“画像”，为项目提供宝贵直觉。

4.3 原语塌缩检测与缓解方案

分析目的： 识别模型中是否存在原语塌缩现象，即部分原语在训练中未被有效使用或学到重复的功能，以及探讨可能的缓解方案。原语塌缩会降低模型实际有效容量和多样性，不利于模型性能和解释性。

检测方法： 利用以上4.1和4.2的结果，从多角度判断塌缩：

使用频率：如果某些原语在整个测试集中选中的频率几乎为0%，可判定它们在训练中遭到了忽略。在的示例结果中，原语1未被使用，就是明显的塌缩案例。

输出相似度：计算所有原语算子对同一输入的输出差异。如果对于任意输入，一组原语的输出恒近似比例关系，则这些原语功能冗余。例如用4.2中的皮尔逊系数矩阵，寻找是否有不同 $i,j$ 对满足 $\Delta u_i \approx k \cdot \Delta u_j$（相关度≈1且比例常近似常数）。

梯度检查：在训练末期，查看每个原语算子参数的梯度范数或更新幅度。如果某原语的参数几乎不再更新，且loss对其不敏感，说明其贡献很小，可以视为塌缩。

缓解方案实验： 针对可能发生的塌缩问题，我们提出并验证以下策略：

增加路由均衡正则： 当前仅用熵正则鼓励每步使用多个原语。可引入MoE论文常用的负载均衡损失，鼓励每个原语获得均衡的总使用量。例如在loss中加入$\sum_j (p_j - \frac{1}{N_p})^2$，其中$p_j$是第$j$个原语被选中的频率（可以按batch统计近似）。实验上可训练两个模型对比：一个加入该正则项，一个不加，观察是否前者的原语使用更为均衡而性能无显著下降。

随机路由或温度调度： 在训练早期，为了探索，可以将路由器softmax的温度设高一些（或不使用top-k）使更多原语参与，然后逐步降低温度恢复稀疏。或者每隔一定步长，随机激活一些原本不在Top-k的原语（类似gating dropout的思想），强制让它们也获得梯度更新。我们可以尝试在若干训练实验中应用这些技巧并监控塌缩改善情况。

原语重新初始化： 如果发现某些原语长期闲置且输出接近0或无用，我们可以在训练中途将其参数重新随机初始化，观察能否被重新利用上（这有点类似于神经网络训练中遇到“死亡”节点时的处理）。不过此方法需谨慎，可能干扰稳定训练，但作为实验可以在后期尝试，以提高最终原语利用率。

评估指标： 对每项缓解方案，我们主要关注：(1) 原语利用率提升：比如加入均衡正则后，每个原语的使用频率是否更加接近平均值25%/16%等（具体因Top-k而异）。(2) 性能变化：防塌缩措施可能牺牲部分拟合能力，因此比较新方案模型的验证/测试误差相对于原方案有无明显变化。如果几乎不变或更好，则说明此措施可取；若性能显著下降，则说明塌缩也许是模型自身做出的正当调节（可能某些原语确实冗余）。(3) 原语多样性：利用多样性指标和输出差异度再次评估，各原语输出是否变得更不同了（例如 diversity loss 值降低表示输出更正交）。如果成功缓解塌缩，应看到未使用原语开始产生与其他原语不同的新功能。

实现建议： 均衡正则可在训练loss计算处加入一项。例如每个batch计算平均权重向量的平方和，或使用在全局统计上实现则需要累积计数，这可通过在每epoch结束时基于路由统计来更新loss（相当于离线调整，不太标准但可尝试）。温度调节可以将softmax改为带温度$\tau$，逐epoch降低$\tau$从1降到0.5等，看哪种曲线效果好。这些在实现时都需确保不会破坏原训练流程。为了方便试验，也可以从小规模数据集入手调参，再转全数据。注意：评价塌缩缓解应该基于相同训练轮次比较，否则单纯延长训练也可能逐步利用更多原语（要排除训练时长因素）。最终，记录各方法的原语使用频谱图，将有助于直观比较。

4.4 组合路径的可解释性分析

分析目的： 从全局角度审视模型针对不同PDE和状态所采用的原语组合路径，评估这些路径是否与人类对方程组成的理解一致，从而增强模型的可解释性。例如，对于组合模型，我们希望能够解释：“在某PDE上，模型主要走哪几条原语通路实现动力学近似”，类似地看不同PDE之间路径的异同。

分析方法：

不同PDE的组合对比： 利用4.1节所得的每类PDE的原语使用统计，提取出每类PDE最常用的 Top-2 原语组合。例如发现PDE_A经常使用{原语2, 原语5}，而PDE_B偏好{原语5, 原语6}。将这些结果与这两个PDE在物理上组成的项对比：如果PDE_A对应某种组合项，而{2,5}原语恰与其匹配，则证明模型的组合路径有物理合理性。如有文献先验知识（例如CompNO预设了对流和扩散算子来组合），可对照我们自动发现的组合，看是否类似。

同一PDE不同参数下路径变化： 对于参数可变的PDE（如粘性系数不同的Burgers），分析路由器输出随参数的变化规律。例如粘性$\nu$大时是否权重更多分配给扩散型原语，$\nu$小时偏向对流型原语。这可通过固定多个$\nu$的初始条件，计算各自的原语权重平均值来验证。如果发现权重与参数呈单调关系，就说明模型学到了参数对动力学的重要影响。

单次演化过程的路径跟踪： 针对一个具体的PDE初值，记录随时间推进每步的原语选择和权重。例如对一个Burgers方程波破碎的过程，我们期待在最初线性阶段，模型可能同时使用对流和扩散原语，而当形成陡峭波-front时，可能转而更多依赖某一原语来处理剧烈梯度。绘制时间 vs 原语权重的曲线，可以呈现这种切换。例如$t=0$-10阶段$\alpha_{5}$逐渐增大代表扩散加强，等等。若这种变化与物理预期一致（如黏性耗散随时间累积增强影响），说明模型的路由决策在一定程度上可解释。

决策边界近似： 如果需要更深入，可尝试从路由器的 MLP 提取决策规则。由于路由输入是如均值、方差等，可在二维平面上绘制路由选择策略：例如以(mean,std)为坐标，标注出路由器会选择哪两个原语为主。这样可以近似看到决策边界：比如可能std很大(意味着剧烈变化)时偏好某原语，mean值改变影响另一个原语使用等。虽然MLP不是线性规则，但可以采用网格采样观察输出权重分布。

解释结果： 将上述分析整理后，可以为模型提供一种“组合逻辑”的描述。例如：“对于扩散主导的问题，路由器检测到场的方差较小而倾向激活扩散型原语；对于含冲击的对流问题，由于出现高峰值和大梯度，路由选择了包含非线性对流项的原语进行更新”等。这种描述可以得到实验数据支撑，如统计表格或曲线。的研究也支持这种观点：简单线性组合不足时，模型会转而需要更复杂组合。我们通过路由权重随条件变化的模式，可以直观地解释模型在做什么决策。例如，如果发现某一原语几乎恒与另一原语一起被选用，说明这两个原语可能形成固定搭配去近似某完整物理项（比如一个负责线性部分，一个负责非线性部分，一起才能还原完整动力学）。

实现建议： 这部分主要是对前面所得数据进一步加工和解释。可以将4.1收集的原语使用频率矩阵进行归一化，突出每类PDE的主导原语组合。对于参数分析，编写脚本生成一系列不同参数的初值（例如不同$\nu$的同样初始场），用训练好的模型分别计算路由输出，然后绘制权重 vs 参数曲线。如果项目已有多参数训练数据，也可以直接按参数值分类聚合已有评估输出。时间演化路径则直接利用模型对一个长序列做rollout，每步存权重。注意需要关闭训练随机性（如若有dropout之类）以得到确定输出。最后，决策边界可在路由器特征空间采样，如取mean和std在一定范围网格上，计算路由器输出的最大权重原语种类，绘制分域图。这虽然近似（因为实际路由特征还包括min/max等），但可降低维度帮助理解。综合这些结果，撰写报告时可配合示意性图表，以增强说服力，证明我们的模型决策过程符合物理直觉和可解释原则。

以上实验扩展计划涵盖了模型架构、训练策略、任务范围和结果分析等多个方面。通过这些系统性的实验，我们将能够全面评估 MVP 方法的表现，验证其设计合理性，并探索改进空间。这些实验的结论将为后续基于该项目的开发提供指导，确保模型在更复杂多样的科学计算场景中依然高效、准确且可解释。